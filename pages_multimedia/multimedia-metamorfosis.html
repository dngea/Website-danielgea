<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Brutal delusions</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@400;800&display=swap" rel="stylesheet"> 
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        
        <!-- styles -->
        <!-- <link rel="stylesheet" href="../css/css_individualProjects.css"> -->
        <link rel="stylesheet" href="../css/main.css">
        <link rel="stylesheet" href="../css/main_navigation.css">
        <link rel="stylesheet" href="../css/individual-projects2.css?v=1.0.2">

        <!-- IBM PLEX SANS and Work Sans -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Work+Sans:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
           

</head>


<body>

    <!-- ADD HEADER -->
    <div id="header"></div>


    <!-- BIG CONTAINER 1400px ------- -->
<div class="contenedor">

    <!-- Project Introduction -->
    <div class="container-1000">
        <div class="project">
            <div class="project__content">
                <div class="empty"></div>
                <div class="project__header">
                    <h1>Metamorfosis</h1>
                    <p class="date">December of 2023</p>
                    <p class="location">Porto, Portugal</p>
                </div>
            </div>
            <div class="project__content">
                <div class="technical-rider">
                    <h2>Technical Rider</h2>

                    <h4 class="primary">Tasks</h4>
                    <p>Generative music</p>
                    <p>Generative visuals</p>
                    <p>Narrative</p>

                    <h4 class="primary">Tools</h4>
                    <p>Pure data</p>
                    <p>Touchdesigner</p>
                    <p>Processing</p>
                    
                    <h4 class="primary">Timeline</h4>
                    <p>4 weeks</p>
                    <h4 class="primary">Links</h4>
                    <a href="#"><p>Video prototype</p></a>
                    <a href="#"><p>Pure data patch</p></a>
                </div>

                <div class="summary">
                    <h2>Overview</h2>
                    <p>
                        This project is an audio-reactive performance based on Franz Kafka's “The Metamorphosis.”
                        <br>
                        <br>
                        It uses Processing, Pure Data, and TouchDesigner to create four unique soundscapes, 
                        each developed with Pure Data
                        and controlled through Processing. Live visuals in TouchDesigner will respond to the audio.
                        <br>
                        Each soundscape will represent a phase of the metamorphosis, so it's crucial to transition 
                        smoothly between them to keep the performance cohesive. I will provide more details in the 
                        following points.
                    </p>

                    <h2>Project Goals</h2>
                    <p>
                        The main goals of this project are to create four distinct soundscapes that reflect the 
                        phases of Kafka's “The Metamorphosis” and to ensure smooth transitions between them for 
                        a cohesive audio-reactive performance. The visuals will dynamically respond to the audio 
                        to enhance the overall experience.
                    </p>
                </div>
            </div>
        </div>  
    </div>
    <!-- //Project Introduction -->

    <!-- Case Study Description -->
    <div class="container-1000">
        <div class="case-study">
            <div class="case-study__header">
                <div class="divider"></div>
                <h2><span class="primary">Phase 1.</span> Discover</h2>
                <div class="divider"></div>
            </div>
            <div class="case-study__body">
                <div class="case-study__body--summary">
                    <h3>Goals</h3>
                    <p>User research</p>
                    <p>Trends</p>
                </div>
                <div class="case-study__body--content">
                    <h3>Context</h3>
                    <p>
                        This project is a creative homage to Franz Kafka's The Metamorphosis, blending generative music and reactive visuals to craft a deeply immersive, multi-sensory experience. By integrating the technologies of Processing, Pure Data, and TouchDesigner, it creates a dynamic performance that captures the essence of Kafka’s exploration of transformation and identity.
                        Through the synergy of sound, visuals, and thematic storytelling, the performance offers an evocative exploration of Kafka's themes of change, alienation, and identity, drawing the audience into a compelling artistic interpretation of his seminal work.
                    </p>

                    <h3>Challenges</h3>
                    <p>
                        The performance integrates various synthesis techniques, including Additive, Subtractive, Frequency Modulation (FM), and Granular Synthesis, to craft dynamic and evolving soundscapes.
                    </p>
                    <ul>
                        <li>Seamless Transitions: Ensuring smooth shifts between musical sections to maintain the immersive atmosphere without disrupting the flow.</li>
                        <li>Unified Control: Managing the entire performance with a single controller, providing intuitive access to all features.</li>
                        <li>Real-Time Audio-Visual Synchronization: Creating a cohesive experience by tightly connecting music and visuals in real-time, ensuring that every sound is visually represented.</li>
                        <li>Strong Audio-Visual Synergy: Prioritizing a harmonious and synchronized relationship between audio and imagery to deliver an engaging and cohesive performance.</li>
                    </ul>

                    <h3>References</h3>
                    <ul>
                        <li><strong>Ryoji Ikeda</strong>: A renowned artist known for his minimalist and data-driven audiovisual compositions.</li>
                        <li><strong>"unfold" by Ryoichi Kurokawa</strong>: A performance blending visual art and sound to explore themes of space and time.</li>
                        <li><strong>"Drone"</strong>: A piece available on YouTube, showcasing immersive audio-visual elements.</li>
                        <li><strong>Profiteroles</strong> by <strong>Rino Petrozziello</strong>: Another artwork available on YouTube, featuring unique artistic expression.</li>
                    </ul>
                </div>
            </div>
        </div>


        <div class="case-study">
            <div class="case-study__header">
                <div class="divider"></div>
                <h2><span class="primary">Phase 2.</span> Implementation</h2>
                <div class="divider"></div>
            </div>
            <div class="case-study__body">
                <div class="case-study__body--summary">
                    <h3>Overview</h3>
                    <p>Processing</p>
                    <p>OSC</p>
                    <p>Pure Data</p>
                </div>
                <div class="case-study__body--content">
                    <h3>Processing</h3>
                    <p>One of the biggest challenges in this project was finding a way to control as many parameters as possible with minimal hardware—using fewer sliders, buttons, and controllers. To address this, I developed a <strong>2D slider</strong> to act as the master controller for the entire performance.</p>
                    <p>I designed the 2D slider in <strong>Processing</strong>, focusing on simplicity and functionality. Using basic shapes and tracking mouse positions, I captured the values needed to interact with <strong>Pure Data</strong> effectively. While I won’t dive into the technical details, the core strategies involved:</p>
                    <ul>
                        <li>Defining boundaries for each chapter of the performance to ensure smooth transitions.</li>
                        <li>Using mathematical operations to precisely map the values to fit the requirements of the soundscapes and visuals.</li>
                    </ul>
                    <p>This approach allowed for intuitive, real-time control of multiple variables, enabling seamless coordination across the audio and visual elements of the performance.</p>

                    <h3>OSC</h3>
                    <p>Some of the libraries I was looking at were <strong>oscP5</strong>, <strong>controlP5</strong>, <strong>mrPeach</strong>, and the OSC library (found in the browser of PD). For Processing, the first two libraries were important to start sending values with OSC.</p>
                    <p>The first OSC syntax I tried, using mrPeach and routeOSC, was working but not consistently. I had to repeatedly open and close PD for it to properly read the objects. Eventually, I decided to explore other alternatives.</p>
                    <p>Later, I discovered a solution using the <em>netreceive</em> object, which resolved all issues with receiving OSC messages:</p>
                    <ul>
                        <li>Ensured PD would reliably receive messages from Processing.</li>
                        <li>Streamlined the workflow by avoiding repetitive setup processes.</li>
                    </ul>
                    <p>By implementing this method, I could successfully send and read messages between Processing and PD.</p>

                    <h3>Pure Data</h3>
                    <p>The performance is divided into <strong>four chapters</strong>, each representing a distinct phase of the metamorphosis:</p>
                    <ol>
                        <li><strong>Awakening</strong> – The break from silence and sleep, signaling the start of transformation.</li>
                        <li><strong>Negation and Lostness</strong> – A phase of resistance and disorientation, marking the onset of change.</li>
                        <li><strong>Metamorphosis</strong> – The moment of no return, where transformation fully takes shape.</li>
                        <li><strong>Acceptance and New Reality</strong> – A return to calm, embracing the changes that define the new reality.</li>
                    </ol>
                    <p>Each chapter is represented by its own <strong>soundscape</strong>, carefully designed to reflect its unique feeling and rhythm while maintaining continuity as part of a cohesive performance.</p>

                    <h4>Creating Continuity and Differentiation</h4>
                    <p>The performance revolves around <strong>four main notes</strong>, introduced sequentially in the first chapter. These notes act as the core of the soundscapes, manipulated through changes in rhythm, reverb, oscillators, and scales to provide both continuity and differentiation across chapters.</p>
                    <p>For added tension and resolution, dissonant notes were derived by shifting main note values up or down various scales. This balance was achieved through experimentation and iteration.</p>

                    <h4>Techniques and Sound Design</h4>
                    <ul>
                        <li><strong>Additive Synthesis:</strong> Combined frequencies into chords, transitioning between major, minor, augmented, and diminished modes.</li>
                        <li><strong>Frequency Modulation (FM):</strong> Introduced dissonance and tension through waveform transitions, symbolizing transformation.</li>
                        <li><strong>Granular Synthesis:</strong> Mimicked insect sounds, aligning with the transformation phase, with dynamically adjusted grain duration.</li>
                        <li><strong>Additional Techniques:</strong>
                            <ul>
                                <li>Panning and delays for spatial depth.</li>
                                <li>Envelopes for dynamic shaping.</li>
                                <li>Random timing for unpredictable metronome effects.</li>
                            </ul>
                        </li>
                    </ul>
                    <h3>TouchDesigner</h3>
                    <p>To send values from <strong>Pure Data (PD)</strong> to <strong>TouchDesigner (TD)</strong>, I utilized <strong>OSC (Open Sound Control)</strong> messages. Initially, this setup worked flawlessly, allowing smooth communication between PD and TD. However, on <strong>January 1st</strong>, the OSC messages suddenly stopped being sent, despite no apparent errors.</p>
                    <p>After troubleshooting, I discovered the issue was related to the syntax and library being used. I eventually found an alternative code that defined the OSC message more clearly and used the <strong>netsend</strong> function for better stability.</p>
                </div>
            
            </div>
        </div>

        <div class="case-study">
            <div class="case-study__header">
                <div class="divider"></div>
                <h2><span class="primary">Phase 3.</span> Results</h2>
                <div class="divider"></div>
            </div>
            <div class="case-study__body">
                <div class="case-study__body--summary">
                    <h3>Overview</h3>
                    <p>Processing</p>
                    <p>OSC</p>
                    <p>Pure Data</p>
                </div>
                <div class="case-study__body--content">
                    <h3>Visual and Performance Outputs</h3>
                    <p>The final results showcased seamless integration of audio and visual elements, representing the metamorphosis journey effectively. Below are snapshots from the performance, highlighting key moments and technical achievements:</p>
                    
                    <div class="case-study__images">
                        <img src="/img/multimedia/metamorfosis/chapter1.png" alt="Snapshot of Awakening chapter with visual effects" />
                        <img src="/img/multimedia/metamorfosis/chapter2.png" alt="Visual representation during Negation and Lostness" />
                        <img src="/img/multimedia/metamorfosis/chapter3.png" alt="Insect-like visuals during Metamorphosis" />
                        <img src="/img/multimedia/metamorfosis/chapter4.png" alt="Calm and accepting visuals during the final chapter" />
                    </div>
                </div>
            </div>
        </div>
        
    </div>


</div>




    <!-- JS ------------- -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <script src="../js/main.js"></script>
</body>
</html>