<!DOCTYPE html>
<html lang="en">
    <head>
  
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-QT916BT4LX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-QT916BT4LX');
    </script>
        <meta charset="UTF-8">
        <title>Metamorphosis</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@400;800&display=swap" rel="stylesheet"> 
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        
        <!-- styles -->
        <!-- <link rel="stylesheet" href="../css/css_individualProjects.css"> -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
        <!-- <link rel="stylesheet" href="../css/main.css?v=1.0.5?v=1.0.2"> -->
        <link rel="stylesheet" href="../css/projects.css?v=1.0.1">
        <link rel="stylesheet" href="../css/main_navigation.css?v=1.0.3">
        <link rel="stylesheet" href="../css/individual-projects2.css?v=1.1.3">

        <!-- IBM PLEX SANS and Work Sans -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Work+Sans:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
           

</head>


<body>

    
    <div id="header"></div>

    <div class="wrapper">
        <!-- BIG CONTAINER 1400px ------- -->
        <div class="contenedor">
            <div class="back">
                <div class="item-back">
                    <svg class="w-[20px] h-[20px] text-gray-800 dark:text-white" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24">
                        <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M5 12h14M5 12l4-4m-4 4 4 4"/>
                    </svg>          
                    <a href="../multimedia.html">Back to projects</a>
                </div>
            </div>
            <!-- overview -->
            <div class="container-1000">
                <div class="project">
                    <div class="project__content">
                        <div class="empty"></div>
                        <div class="project__header">
                            <h1>Metamorphosis</h1>
                            <p class="date">December of 2023</p>
                            <p class="location">Porto, Portugal</p>
                        </div>
                    </div>
                    <div class="project__content">
                        <div class="technical-rider">
                            <div>

                                <h4 class="primary">Tasks</h4>
                                <p>Generative music</p>
                                <p>Generative visuals</p>
                                <p>Storytelling</p>
            
                                <h4 class="primary">Tools</h4>
                                <p>Pure data</p>
                                <p>TouchDesigner</p>
                                <p>Processing</p>
                            </div>

                            <div>
                                <h4 class="primary">Timeline</h4>
                                <p>4 weeks</p>
                                <h4 class="primary">Links</h4>
                                <a href="https://drive.google.com/file/d/1we_mYO_8WAB17_V0gtX6uuCGjK5_uAfE/view?usp=sharing" target="_blank"><p>Video demo performance</p></a>
                                <a href="https://github.com/dngea/metamorfosis-audiovisual-reactive-performance" target="_blank"><p>Pure data patch</p></a>

                            </div>
                        </div>

                        <div class="summary">
                            <h2>Overview</h2>
                            <p>
                            I developed an immersive, interactive performance inspired by Franz Kafka's The Metamorphosis, combining real-time sound and generative visuals to create a cohesive narrative experience. Over four weeks, I designed and implemented four distinct soundscapes using Pure Data, each representing a phase of the metamorphosis, and created reactive visuals in TouchDesigner. I developed the UI controls in Processing and integrated all components seamlessly using OSC protocols, ensuring smooth transitions between soundscapes and visuals.
                            </p>

                            <h2>Project Goals</h2>
                            <p>
                                The main goals of this project are to create four distinct soundscapes that reflect the 
                                phases of Kafka's “The Metamorphosis” and to ensure smooth transitions between them for 
                                a cohesive audio-reactive performance. The visuals will dynamically respond to the audio 
                                to enhance the overall experience.
                            </p>
                        </div>
                    </div>
                </div>  
            </div>

            <!-- content -->
            <main class="container-1000">
                <div class="case-study">
                    <div class="case-study__header">
                        <div class="divider"></div>
                        <h2><span class="primary">01</span> Discover</h2>
                        <div class="divider"></div>
                    </div>
                    <div class="case-study__body">
                            <h3>Context</h3>
                            <p>
                                This project is a creative homage to Franz Kafka's The Metamorphosis, blending generative music and reactive visuals to craft a deeply immersive, multi-sensory experience. By integrating the technologies of Processing, Pure Data, and TouchDesigner, it creates a dynamic performance that captures the essence of Kafka’s exploration of transformation and identity.
                                Through the synergy of sound, visuals, and thematic storytelling, the performance offers an evocative exploration of Kafka's themes of change, alienation, and identity, drawing the audience into a compelling artistic interpretation of his seminal work.
                            </p>

                            <h3>Challenges</h3>
                            <p>
                                The performance integrates various synthesis techniques, including Additive, Subtractive, Frequency Modulation (FM), and Granular Synthesis, to craft dynamic and evolving soundscapes.
                            </p>
                            <ul>
                                <li>Seamless Transitions: Ensuring smooth shifts between musical sections to maintain the immersive atmosphere without disrupting the flow.</li>
                                <li>Unified Control: Managing the entire performance with a single controller, providing intuitive access to all features.</li>
                                <li>Real-Time Audio-Visual Synchronization: Creating a cohesive experience by tightly connecting music and visuals in real-time, ensuring that every sound is visually represented.</li>
                                <li>Strong Audio-Visual Synergy: Prioritizing a harmonious and synchronized relationship between audio and imagery to deliver an engaging and cohesive performance.</li>
                            </ul>

                            <h3>References</h3>
                            <ul>
                                <li><strong>Ryoji Ikeda</strong>: A renowned artist known for his minimalist and data-driven audiovisual compositions.</li>
                                <li><strong>"unfold" by Ryoichi Kurokawa</strong>: A performance blending visual art and sound to explore themes of space and time.</li>
                                <li><strong>"Drone"</strong>: A piece available on YouTube, showcasing immersive audio-visual elements.</li>
                                <li><strong>Profiteroles</strong> by <strong>Rino Petrozziello</strong>: Another artwork available on YouTube, featuring unique artistic expression.</li>
                            </ul>
                        
                    </div>
                </div>


                <div class="case-study">
                    <div class="case-study__header">
                        <div class="divider"></div>
                        <h2><span class="primary">02</span> Implementation</h2>
                        <div class="divider"></div>
                    </div>
                    <div class="case-study__body">

                            <h3>Processing</h3>
                            <p>One of the biggest challenges in this project was finding a way to control as many parameters as possible with minimal hardware—using fewer sliders, buttons, and controllers. To address this, I developed a <strong>2D slider</strong> to act as the master controller for the entire performance.</p>
                            <p>I designed the 2D slider in <strong>Processing</strong>, focusing on simplicity and functionality. Using basic shapes and tracking mouse positions, I captured the values needed to interact with <strong>Pure Data</strong> effectively. While I won’t dive into the technical details, the core strategies involved:</p>
                            <ul>
                                <li>Defining boundaries for each chapter of the performance to ensure smooth transitions.</li>
                                <li>Using mathematical operations to precisely map the values to fit the requirements of the soundscapes and visuals.</li>
                            </ul>
                            <p>This approach allowed for intuitive, real-time control of multiple variables, enabling seamless coordination across the audio and visual elements of the performance.</p>

                            <div class="case-study__images">
                                <img src="/img/multimedia/metamorfosis/slider.png" alt="Slider control in Processing" />
                            </div>

                            <h3>OSC</h3>
                            <p>Some of the libraries I was looking at were <strong>oscP5</strong>, <strong>controlP5</strong>, <strong>mrPeach</strong>, and the OSC library (found in the browser of PD). For Processing, the first two libraries were important to start sending values with OSC.</p>
                            <p>The first OSC syntax I tried, using mrPeach and routeOSC, was working but not consistently. I had to repeatedly open and close PD for it to properly read the objects. Eventually, I decided to explore other alternatives.</p>
                            <p>Later, I discovered a solution using the <em>netreceive</em> object, which resolved all issues with receiving OSC messages:</p>
                            <ul>
                                <li>Ensured PD would reliably receive messages from Processing.</li>
                                <li>Streamlined the workflow by avoiding repetitive setup processes.</li>
                            </ul>
                            <p>By implementing this method, I could successfully send and read messages between Processing and PD.</p>

                            <div class="case-study__images">
                                <img src="/img/multimedia/metamorfosis/osc.png" alt="Netreceive OSC Pure data" />
                            </div>

                            <h3>Pure Data</h3>
                            <p>The performance is divided into <strong>four chapters</strong>, each representing a distinct phase of the metamorphosis:</p>
                            <ol>
                                <li><strong>Awakening</strong> – The break from silence and sleep, signaling the start of transformation.</li>
                                <li><strong>Negation and Lostness</strong> – A phase of resistance and disorientation, marking the onset of change.</li>
                                <li><strong>Metamorphosis</strong> – The moment of no return, where transformation fully takes shape.</li>
                                <li><strong>Acceptance and New Reality</strong> – A return to calm, embracing the changes that define the new reality.</li>
                            </ol>
                            <p>Each chapter is represented by its own <strong>soundscape</strong>, carefully designed to reflect its unique feeling and rhythm while maintaining continuity as part of a cohesive performance.</p>

                            <h4>Creating Continuity and Differentiation</h4>
                            <p>The performance revolves around <strong>four main notes</strong>, introduced sequentially in the first chapter. These notes act as the core of the soundscapes, manipulated through changes in rhythm, reverb, oscillators, and scales to provide both continuity and differentiation across chapters.</p>
                            <p>For added tension and resolution, dissonant notes were derived by shifting main note values up or down various scales. This balance was achieved through experimentation and iteration.</p>

                            <h4>Techniques and Sound Design</h4>
                            <ol>
                                <li><strong>Additive Synthesis:</strong> Combined frequencies into chords, transitioning between major, minor, augmented, and diminished modes.</li>
                                <li><strong>Frequency Modulation (FM):</strong> Introduced dissonance and tension through waveform transitions, symbolizing transformation.</li>
                                <li><strong>Granular Synthesis:</strong> Mimicked insect sounds, aligning with the transformation phase, with dynamically adjusted grain duration.</li>
                                <li><strong>Additional Techniques:</strong>
                                    <ul>
                                        <li>Panning and delays for spatial depth.</li>
                                        <li>Envelopes for dynamic shaping.</li>
                                        <li>Random timing for unpredictable metronome effects.</li>
                                    </ul>
                                </li>
                            </ol>
                            <h3>TouchDesigner</h3>
                            <p>To send values from <strong>Pure Data (PD)</strong> to <strong>TouchDesigner (TD)</strong>, I utilized <strong>OSC (Open Sound Control)</strong> messages. Initially, this setup worked flawlessly, allowing smooth communication between PD and TD. However, on <strong>January 1st</strong>, the OSC messages suddenly stopped being sent, despite no apparent errors.</p>
                            <p>After troubleshooting, I discovered the issue was related to the syntax and library being used. I eventually found an alternative code that defined the OSC message more clearly and used the <strong>netsend</strong> function for better stability.</p>
                        
                    
                    </div>
                </div>

                <div class="case-study">
                    <div class="case-study__header">
                        <div class="divider"></div>
                        <h2><span class="primary">03</span> Results</h2>
                        <div class="divider"></div>
                    </div>
                    <div class="case-study__body">

                            <h3>Visual and Performance Outputs</h3>
                            <p>The final results showcased seamless integration of audio and visual elements, representing the metamorphosis journey effectively. Below are snapshots from the performance, highlighting key moments and technical achievements:</p>
                            
                            <div class="case-study__images">
                                <img src="/img/multimedia/metamorfosis/chapter1.png" alt="Snapshot of Awakening chapter with visual effects" />
                                <img src="/img/multimedia/metamorfosis/chapter2.png" alt="Visual representation during Negation and Lostness" />
                                <img src="/img/multimedia/metamorfosis/chapter3.png" alt="Insect-like visuals during Metamorphosis" />
                                <img src="/img/multimedia/metamorfosis/chapter4.png" alt="Calm and accepting visuals during the final chapter" />
                            </div>
                        
                    </div>
                </div>
                
            </main>

        </div>
    </div>

    <footer id="footer" class="footer"></footer>


    <!-- JS ------------- -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <script src="../js/main.js"></script>
</body>
</html>